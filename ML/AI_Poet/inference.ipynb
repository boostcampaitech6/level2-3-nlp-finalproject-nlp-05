{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "f4vrUGkBp7DZ"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rJWI3XmoqQW9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AKI_hmnnqjPo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"output/checkpoint-13000\").to(device)\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\",\n",
        "  bos_token='<s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(51201, 1920)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.add_special_tokens({'additional_special_tokens': [\"<yun>\"]})\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = '<s>떠나간 봄날의 설레는 기다림\\n'\n",
        "inputs = tokenizer.encode(sentence, add_special_tokens=True, return_tensors='pt').to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids=inputs,\n",
        "        temperature=0.6, # 생성 다양성 조절\n",
        "        min_length=64, # 생성되는 문장의 최소 길이\n",
        "        max_length=256, # 생성되는 문장의 최대 길이\n",
        "        repetition_penalty=1.2, # 반복을 줄이는 패널티\n",
        "        do_sample=True, # 샘플링 기반 생성 활성화\n",
        "        early_stopping=True, # EOS token을 만나면 조기 종료\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        top_k=10,\n",
        "        top_p=0.95\n",
        "    )\n",
        "\n",
        "generated_sequence = output[0].tolist()\n",
        "text = tokenizer.decode(generated_sequence, skip_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = text.replace(\"<yun> \", \"\\n\").replace(\"<s> \", \"\").replace(\"</s>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "떠나간 봄날의 설레는 기다림\n",
            "그리움으로 다시 찾아온 봄의 향기\n",
            "\n",
            "그 옛날 보릿고개 넘을 때 \n",
            "마지막 이었던 매화꽃 피던 날\n",
            "가슴에 살며시 물결치는 그리움\n",
            "\n",
            "새봄이 돌아오면 꽃잎은 더 푸르고\n",
            "살랑이는 봄바람 불 때면 옛 추억에\n",
            "잠겨오는 아련한 첫사랑의 연가\n",
            "\n",
            "목련의 고귀한 순결함처럼\n",
            "그대의 따사한 눈길 속에 피는\n",
            "곱디 고운 사랑의 미로\n",
            "\n",
            "춘삼월엔 맘 속 깊숙하게 파고드는\n",
            "아름다운 사랑 노래하고픈데\n",
            "보리피리 만들어 부르면서\n",
            "첫사랑의 향연 그리워하네\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN+1o7ZT89AaH0RyjJRww3h",
      "include_colab_link": true,
      "name": "3. Generater.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
